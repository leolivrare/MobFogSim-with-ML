{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "bKOf490Zomqh",
        "Ecj-HGMfoqpH"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dependências e Imports\n",
        "\n",
        "Nesta seção, instalamos e importamos as bibliotecas necessárias.\n",
        "A biblioteca Flower (flwr) é usada para simular o treinamento federado.\n",
        "Também utilizamos PyTorch para definir e treinar o modelo de Machine Learning.\n"
      ],
      "metadata": {
        "id": "J1_7h3rmohQr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Xtr8KgwDEcW6"
      },
      "outputs": [],
      "source": [
        "!pip install -q flwr[simulation] flwr-datasets[vision] torch torchvision matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importações das dependências e setup do dispositivo.\n",
        "# Aqui, determinamos se o treinamento será em CPU ou GPU.\n",
        "# Em seguida, imprimimos as versões para checagem.\n",
        "\n",
        "from collections import OrderedDict\n",
        "from typing import List, Tuple, Optional, Union\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import flwr\n",
        "from flwr.client import NumPyClient, ClientApp\n",
        "from flwr.common import Context, Metrics, Parameters, parameters_to_ndarrays, ndarrays_to_parameters\n",
        "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
        "from flwr.server.strategy import FedAvg\n",
        "from flwr.simulation import run_simulation\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Training on {DEVICE}\")\n",
        "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")\n",
        "\n",
        "# Diretório com os dados dos dispositivos\n",
        "DATA_DIR = \"devices_logs/\"\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fg3I2cAAEj9J",
        "outputId": "f3ebd277-84f7-454c-840a-7781a2f92cce"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cpu\n",
            "Flower 1.13.1 / PyTorch 2.5.1+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploração dos dados para treinamento\n",
        "\n",
        "Nesta seção, carregamos e exploramos os dados do simulador. O objetivo é entender sua distribuição antes de configurar o treinamento federado.\n",
        "Cada dispositivo (client) terá seu próprio subconjunto de dados, simulando um cenário federado.\n"
      ],
      "metadata": {
        "id": "bKOf490Zomqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para carregar e analisar os dados.\n",
        "# Isso nos ajuda a entender a distribuição de casos 'ShouldMigrate=True' e 'ShouldMigrate=False'\n",
        "# antes de montar o esquema de treinamento federado.\n",
        "\n",
        "def load_data(data_dir):\n",
        "    data = {}\n",
        "    for filename in os.listdir(data_dir):\n",
        "        if filename.endswith(\".csv\"):\n",
        "            device_id = int(filename.split(\"_\")[1])\n",
        "            filepath = os.path.join(data_dir, filename)\n",
        "            df = pd.read_csv(filepath, delimiter=\";\")\n",
        "\n",
        "            if device_id not in data:\n",
        "                data[device_id] = []\n",
        "\n",
        "            data[device_id].append(df)\n",
        "\n",
        "    for device_id in data:\n",
        "        combined_df = pd.concat(data[device_id], ignore_index=True)\n",
        "        data[device_id] = combined_df.drop_duplicates(\n",
        "            subset=[\"Time\", \"DeviceId\", \"Speed\", \"DistanceToSourceAp\",\n",
        "                    \"DistanceToLocalCloudlet\", \"ShouldMigrate\", \"IsMigPoint\", \"IsMigZone\"]\n",
        "        )\n",
        "\n",
        "    return data\n",
        "\n",
        "def analyze_data(data):\n",
        "    for device_id, df in data.items():\n",
        "        true_cases = df[df['ShouldMigrate'] == True]\n",
        "        false_cases = df[df['ShouldMigrate'] == False]\n",
        "\n",
        "        true_count = len(true_cases)\n",
        "        false_count = len(false_cases)\n",
        "        total_count = len(df)\n",
        "        print(f\"Device {device_id}:\")\n",
        "        print(f\"  Total cases: {total_count}\")\n",
        "        print(f\"  True (shouldMigrate = True): {true_count} ({(true_count / total_count) * 100:.2f}%)\")\n",
        "        print(f\"  False (shouldMigrate = False): {false_count} ({(false_count / total_count) * 100:.2f}%)\")\n",
        "\n",
        "        print(\"\\n  Examples where ShouldMigrate = True:\")\n",
        "        print(true_cases[['Time', 'DeviceId', 'Speed', 'DistanceToSourceAp',\n",
        "                          'DistanceToLocalCloudlet', 'ShouldMigrate', 'IsMigPoint', 'IsMigZone']].head(3))\n",
        "        print(\"\\n  Examples where ShouldMigrate = False:\")\n",
        "        print(false_cases[['Time', 'DeviceId', 'Speed', 'DistanceToSourceAp',\n",
        "                           'DistanceToLocalCloudlet', 'ShouldMigrate', 'IsMigPoint', 'IsMigZone']].head(3))\n",
        "        print(\"\\n\" + \"-\"*50)\n",
        "\n",
        "data = load_data(DATA_DIR)\n",
        "analyze_data(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5hMT2SJofpN",
        "outputId": "3f2309c9-fdd6-4ecb-89ed-7545409d68b8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device 4:\n",
            "  Total cases: 138\n",
            "  True (shouldMigrate = True): 2 (1.45%)\n",
            "  False (shouldMigrate = False): 136 (98.55%)\n",
            "\n",
            "  Examples where ShouldMigrate = True:\n",
            "         Time  DeviceId  Speed  DistanceToSourceAp  DistanceToLocalCloudlet  \\\n",
            "109  150000.0         4     13          953.495674               953.495674   \n",
            "179  110000.0         4     13          592.190848               592.190848   \n",
            "\n",
            "     ShouldMigrate  IsMigPoint  IsMigZone  \n",
            "109           True        True       True  \n",
            "179           True        True       True  \n",
            "\n",
            "  Examples where ShouldMigrate = False:\n",
            "      Time  DeviceId  Speed  DistanceToSourceAp  DistanceToLocalCloudlet  \\\n",
            "0  41000.0         4      0          529.555474               529.555474   \n",
            "1  42000.0         4      2          529.306150               529.306150   \n",
            "2  43000.0         4      4          529.395882               529.395882   \n",
            "\n",
            "   ShouldMigrate  IsMigPoint  IsMigZone  \n",
            "0          False       False      False  \n",
            "1          False       False      False  \n",
            "2          False       False      False  \n",
            "\n",
            "--------------------------------------------------\n",
            "Device 7:\n",
            "  Total cases: 1005\n",
            "  True (shouldMigrate = True): 7 (0.70%)\n",
            "  False (shouldMigrate = False): 998 (99.30%)\n",
            "\n",
            "  Examples where ShouldMigrate = True:\n",
            "          Time  DeviceId  Speed  DistanceToSourceAp  DistanceToLocalCloudlet  \\\n",
            "369   423000.0         7     14          960.633645               960.633645   \n",
            "551  1052000.0         7     14          950.588239              2768.452636   \n",
            "801  1755000.0         7     14          958.428401              2818.408948   \n",
            "\n",
            "     ShouldMigrate  IsMigPoint  IsMigZone  \n",
            "369           True        True       True  \n",
            "551           True        True       True  \n",
            "801           True        True       True  \n",
            "\n",
            "  Examples where ShouldMigrate = False:\n",
            "      Time  DeviceId  Speed  DistanceToSourceAp  DistanceToLocalCloudlet  \\\n",
            "0  55000.0         7      0          406.831661               406.831661   \n",
            "1  56000.0         7      2          405.455300               405.455300   \n",
            "2  57000.0         7      3          401.851963               401.851963   \n",
            "\n",
            "   ShouldMigrate  IsMigPoint  IsMigZone  \n",
            "0          False       False      False  \n",
            "1          False       False      False  \n",
            "2          False       False      False  \n",
            "\n",
            "--------------------------------------------------\n",
            "Device 6:\n",
            "  Total cases: 856\n",
            "  True (shouldMigrate = True): 8 (0.93%)\n",
            "  False (shouldMigrate = False): 848 (99.07%)\n",
            "\n",
            "  Examples where ShouldMigrate = True:\n",
            "          Time  DeviceId  Speed  DistanceToSourceAp  DistanceToLocalCloudlet  \\\n",
            "221   263000.0         6     15          956.276111               956.276111   \n",
            "352   841000.0         6      9          952.536089              2284.472149   \n",
            "537  1479000.0         6     15          953.134303               953.134303   \n",
            "\n",
            "     ShouldMigrate  IsMigPoint  IsMigZone  \n",
            "221           True        True       True  \n",
            "352           True        True       True  \n",
            "537           True        True       True  \n",
            "\n",
            "  Examples where ShouldMigrate = False:\n",
            "      Time  DeviceId  Speed  DistanceToSourceAp  DistanceToLocalCloudlet  \\\n",
            "0  42000.0         6      0          666.273968               666.273968   \n",
            "1  43000.0         6      2          665.433693               665.433693   \n",
            "2  44000.0         6      4          663.460624               663.460624   \n",
            "\n",
            "   ShouldMigrate  IsMigPoint  IsMigZone  \n",
            "0          False       False      False  \n",
            "1          False       False      False  \n",
            "2          False       False      False  \n",
            "\n",
            "--------------------------------------------------\n",
            "Device 5:\n",
            "  Total cases: 115\n",
            "  True (shouldMigrate = True): 2 (1.74%)\n",
            "  False (shouldMigrate = False): 113 (98.26%)\n",
            "\n",
            "  Examples where ShouldMigrate = True:\n",
            "         Time  DeviceId  Speed  DistanceToSourceAp  DistanceToLocalCloudlet  \\\n",
            "91   132000.0         5     10          952.463123               952.463123   \n",
            "230   87000.0         5     10          731.272863               731.272863   \n",
            "\n",
            "     ShouldMigrate  IsMigPoint  IsMigZone  \n",
            "91            True        True       True  \n",
            "230           True        True       True  \n",
            "\n",
            "  Examples where ShouldMigrate = False:\n",
            "      Time  DeviceId  Speed  DistanceToSourceAp  DistanceToLocalCloudlet  \\\n",
            "0  41000.0         5      0          741.555797               741.555797   \n",
            "1  42000.0         5      2          740.939944               740.939944   \n",
            "2  43000.0         5      4          740.678743               740.678743   \n",
            "\n",
            "   ShouldMigrate  IsMigPoint  IsMigZone  \n",
            "0          False       False      False  \n",
            "1          False       False       True  \n",
            "2          False       False      False  \n",
            "\n",
            "--------------------------------------------------\n",
            "Device 0:\n",
            "  Total cases: 185\n",
            "  True (shouldMigrate = True): 4 (2.16%)\n",
            "  False (shouldMigrate = False): 181 (97.84%)\n",
            "\n",
            "  Examples where ShouldMigrate = True:\n",
            "         Time  DeviceId  Speed  DistanceToSourceAp  DistanceToLocalCloudlet  \\\n",
            "53    57000.0         0     11          956.882960               956.882960   \n",
            "163  613000.0         0     13          958.501435              4648.268172   \n",
            "166    6000.0         0      4          650.169209               650.169209   \n",
            "\n",
            "     ShouldMigrate  IsMigPoint  IsMigZone  \n",
            "53            True        True       True  \n",
            "163           True        True       True  \n",
            "166           True        True       True  \n",
            "\n",
            "  Examples where ShouldMigrate = False:\n",
            "     Time  DeviceId  Speed  DistanceToSourceAp  DistanceToLocalCloudlet  \\\n",
            "0  4000.0         0      0          646.623538               646.623538   \n",
            "1  5000.0         0      2          648.266920               648.266920   \n",
            "2  6000.0         0      4          650.169209               650.169209   \n",
            "\n",
            "   ShouldMigrate  IsMigPoint  IsMigZone  \n",
            "0          False       False      False  \n",
            "1          False       False       True  \n",
            "2          False       False       True  \n",
            "\n",
            "--------------------------------------------------\n",
            "Device 3:\n",
            "  Total cases: 1512\n",
            "  True (shouldMigrate = True): 9 (0.60%)\n",
            "  False (shouldMigrate = False): 1503 (99.40%)\n",
            "\n",
            "  Examples where ShouldMigrate = True:\n",
            "          Time  DeviceId  Speed  DistanceToSourceAp  DistanceToLocalCloudlet  \\\n",
            "332   369000.0         3     12          953.650355               953.650355   \n",
            "510   999000.0         3      7          948.410249              2825.896318   \n",
            "893  1838000.0         3     12          950.731297              4742.152465   \n",
            "\n",
            "     ShouldMigrate  IsMigPoint  IsMigZone  \n",
            "332           True        True       True  \n",
            "510           True        True       True  \n",
            "893           True        True       True  \n",
            "\n",
            "  Examples where ShouldMigrate = False:\n",
            "      Time  DeviceId  Speed  DistanceToSourceAp  DistanceToLocalCloudlet  \\\n",
            "0  38000.0         3      0          666.273968               666.273968   \n",
            "1  39000.0         3      2          665.433693               665.433693   \n",
            "2  40000.0         3      3          663.460624               663.460624   \n",
            "\n",
            "   ShouldMigrate  IsMigPoint  IsMigZone  \n",
            "0          False       False      False  \n",
            "1          False       False      False  \n",
            "2          False       False      False  \n",
            "\n",
            "--------------------------------------------------\n",
            "Device 8:\n",
            "  Total cases: 1823\n",
            "  True (shouldMigrate = True): 88 (4.83%)\n",
            "  False (shouldMigrate = False): 1735 (95.17%)\n",
            "\n",
            "  Examples where ShouldMigrate = True:\n",
            "         Time  DeviceId  Speed  DistanceToSourceAp  DistanceToLocalCloudlet  \\\n",
            "62  9117000.0         8     14          342.013158               342.013158   \n",
            "63  9118000.0         8     13          356.001404               356.001404   \n",
            "64  9119000.0         8     10          367.005450               367.005450   \n",
            "\n",
            "    ShouldMigrate  IsMigPoint  IsMigZone  \n",
            "62           True        True       True  \n",
            "63           True        True       True  \n",
            "64           True        True       True  \n",
            "\n",
            "  Examples where ShouldMigrate = False:\n",
            "        Time  DeviceId  Speed  DistanceToSourceAp  DistanceToLocalCloudlet  \\\n",
            "0  9055000.0         8      0          170.695636               170.695636   \n",
            "1  9056000.0         8      2          169.567096               169.567096   \n",
            "2  9057000.0         8      4          166.460205               166.460205   \n",
            "\n",
            "   ShouldMigrate  IsMigPoint  IsMigZone  \n",
            "0          False       False      False  \n",
            "1          False       False      False  \n",
            "2          False       False      False  \n",
            "\n",
            "--------------------------------------------------\n",
            "Device 2:\n",
            "  Total cases: 2184\n",
            "  True (shouldMigrate = True): 12 (0.55%)\n",
            "  False (shouldMigrate = False): 2172 (99.45%)\n",
            "\n",
            "  Examples where ShouldMigrate = True:\n",
            "          Time  DeviceId  Speed  DistanceToSourceAp  DistanceToLocalCloudlet  \\\n",
            "247   267000.0         2     11          954.063415               954.063415   \n",
            "441   906000.0         2     14          951.085695              2441.944307   \n",
            "615  1529000.0         2     13          950.354145              2388.075585   \n",
            "\n",
            "     ShouldMigrate  IsMigPoint  IsMigZone  \n",
            "247           True        True       True  \n",
            "441           True        True       True  \n",
            "615           True        True       True  \n",
            "\n",
            "  Examples where ShouldMigrate = False:\n",
            "      Time  DeviceId  Speed  DistanceToSourceAp  DistanceToLocalCloudlet  \\\n",
            "0  23000.0         2      0          682.000733               682.000733   \n",
            "1  24000.0         2      2          681.400029               681.400029   \n",
            "2  25000.0         2      4          678.801886               678.801886   \n",
            "\n",
            "   ShouldMigrate  IsMigPoint  IsMigZone  \n",
            "0          False       False       True  \n",
            "1          False       False      False  \n",
            "2          False       False      False  \n",
            "\n",
            "--------------------------------------------------\n",
            "Device 1:\n",
            "  Total cases: 1152\n",
            "  True (shouldMigrate = True): 13 (1.13%)\n",
            "  False (shouldMigrate = False): 1139 (98.87%)\n",
            "\n",
            "  Examples where ShouldMigrate = True:\n",
            "         Time  DeviceId  Speed  DistanceToSourceAp  DistanceToLocalCloudlet  \\\n",
            "3     26000.0         1      6          585.820792               585.820792   \n",
            "179  648000.0         1     12          585.622745               585.622745   \n",
            "260  103000.0         1     14          948.356473               948.356473   \n",
            "\n",
            "     ShouldMigrate  IsMigPoint  IsMigZone  \n",
            "3             True        True       True  \n",
            "179           True        True       True  \n",
            "260           True        True       True  \n",
            "\n",
            "  Examples where ShouldMigrate = False:\n",
            "      Time  DeviceId  Speed  DistanceToSourceAp  DistanceToLocalCloudlet  \\\n",
            "0  23000.0         1      0          578.088229               578.088229   \n",
            "1  24000.0         1      2          578.858359               578.858359   \n",
            "2  25000.0         1      4          581.945874               581.945874   \n",
            "\n",
            "   ShouldMigrate  IsMigPoint  IsMigZone  \n",
            "0          False       False      False  \n",
            "1          False       False       True  \n",
            "2          False       False       True  \n",
            "\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepara a base de features para treinamento\n",
        "\n",
        "Nesta etapa, criamos um conjunto de dados artificialmente balanceado e simplificado. O objetivo aqui é comprovar a viabilidade do treinamento federado em um contexto onde os dados do dispositivo (client) seriam usados diretamente em um cenário real. Para simplificar o uso do modelo neste estudo, criamos combinações de valores (IsMigPoint/IsMigZone) e labels fixos.\n",
        "\n",
        "Essa abordagem permite focar no objetivo principal do projeto: viabilizar a execução de modelos de Machine Learning no simulador **MobFogSim**, com estudos voltados para treinamento federado. O uso de dados artificiais não prejudica a avaliação do treinamento federado nem o objetivo de plugar o modelo no simulador. Em projetos futuros, o modelo pode ser adaptado para usar dados reais e resolver problemas específicos, mantendo a estrutura federada e a integração com o simulador.\n"
      ],
      "metadata": {
        "id": "Ecj-HGMfoqpH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(data, test_size=0.2, random_state=42):\n",
        "    processed_data = {}\n",
        "\n",
        "    # Gerando amostras sintéticas balanceadas para IsMigPoint/IsMigZone.\n",
        "    # Assim cada dispositivo terá dados balanceados para o treinamento federado.\n",
        "    samples_per_combination = 300\n",
        "    combinations = [\n",
        "        ([0, 0], 0),\n",
        "        ([1, 0], 0),\n",
        "        ([0, 1], 0),\n",
        "        ([1, 1], 1)\n",
        "    ]\n",
        "\n",
        "    for device_id in data.keys():\n",
        "        X_list = []\n",
        "        y_list = []\n",
        "\n",
        "        for (feat, label) in combinations:\n",
        "            arr = np.tile(feat, (samples_per_combination, 1))\n",
        "            X_list.append(arr)\n",
        "            y_list.append(np.full(samples_per_combination, label))\n",
        "\n",
        "        X_all = np.vstack(X_list)\n",
        "        y_all = np.concatenate(y_list)\n",
        "\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X_all, y_all, test_size=test_size, random_state=random_state, stratify=y_all\n",
        "        )\n",
        "\n",
        "        train_size = len(y_train)\n",
        "        val_size = len(y_val)\n",
        "        total_size = train_size + val_size\n",
        "\n",
        "        print(f\"Device {device_id}:\")\n",
        "        print(f\"  Total: {total_size} instâncias\")\n",
        "        print(f\"  Treino: {train_size} ({(train_size/total_size)*100:.2f}%)\")\n",
        "        print(f\"    True: {(y_train==1).sum()} - False: {(y_train==0).sum()}\")\n",
        "        print(f\"  Val: {val_size} ({(val_size/total_size)*100:.2f}%)\")\n",
        "        print(f\"    True: {(y_val==1).sum()} - False: {(y_val==0).sum()}\")\n",
        "        print(\"-\"*50)\n",
        "\n",
        "        processed_data[device_id] = {\n",
        "            \"train\": (X_train, y_train),\n",
        "            \"val\": (X_val, y_val)\n",
        "        }\n",
        "\n",
        "    return processed_data\n",
        "\n",
        "processed_data = preprocess_data(data)"
      ],
      "metadata": {
        "id": "GXoXwi2-F2jo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a38604c5-0b50-4108-8f20-a55587784286"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device 4:\n",
            "  Total: 1200 instâncias\n",
            "  Treino: 960 (80.00%)\n",
            "    True: 240 - False: 720\n",
            "  Val: 240 (20.00%)\n",
            "    True: 60 - False: 180\n",
            "--------------------------------------------------\n",
            "Device 7:\n",
            "  Total: 1200 instâncias\n",
            "  Treino: 960 (80.00%)\n",
            "    True: 240 - False: 720\n",
            "  Val: 240 (20.00%)\n",
            "    True: 60 - False: 180\n",
            "--------------------------------------------------\n",
            "Device 6:\n",
            "  Total: 1200 instâncias\n",
            "  Treino: 960 (80.00%)\n",
            "    True: 240 - False: 720\n",
            "  Val: 240 (20.00%)\n",
            "    True: 60 - False: 180\n",
            "--------------------------------------------------\n",
            "Device 5:\n",
            "  Total: 1200 instâncias\n",
            "  Treino: 960 (80.00%)\n",
            "    True: 240 - False: 720\n",
            "  Val: 240 (20.00%)\n",
            "    True: 60 - False: 180\n",
            "--------------------------------------------------\n",
            "Device 0:\n",
            "  Total: 1200 instâncias\n",
            "  Treino: 960 (80.00%)\n",
            "    True: 240 - False: 720\n",
            "  Val: 240 (20.00%)\n",
            "    True: 60 - False: 180\n",
            "--------------------------------------------------\n",
            "Device 3:\n",
            "  Total: 1200 instâncias\n",
            "  Treino: 960 (80.00%)\n",
            "    True: 240 - False: 720\n",
            "  Val: 240 (20.00%)\n",
            "    True: 60 - False: 180\n",
            "--------------------------------------------------\n",
            "Device 8:\n",
            "  Total: 1200 instâncias\n",
            "  Treino: 960 (80.00%)\n",
            "    True: 240 - False: 720\n",
            "  Val: 240 (20.00%)\n",
            "    True: 60 - False: 180\n",
            "--------------------------------------------------\n",
            "Device 2:\n",
            "  Total: 1200 instâncias\n",
            "  Treino: 960 (80.00%)\n",
            "    True: 240 - False: 720\n",
            "  Val: 240 (20.00%)\n",
            "    True: 60 - False: 180\n",
            "--------------------------------------------------\n",
            "Device 1:\n",
            "  Total: 1200 instâncias\n",
            "  Treino: 960 (80.00%)\n",
            "    True: 240 - False: 720\n",
            "  Val: 240 (20.00%)\n",
            "    True: 60 - False: 180\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelo usado para treinamento\n",
        "\n",
        "Definimos um modelo PyTorch simples (duas camadas fully-connected), suficiente para demonstrar o conceito de treinamento federado.\n",
        "No treinamento federado, cada cliente treina esse modelo localmente e o servidor agrega os parâmetros.\n"
      ],
      "metadata": {
        "id": "NQgXQvBEowKK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MigrationModel(nn.Module):\n",
        "    def __init__(self, input_dim=2):\n",
        "        super(MigrationModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 4)\n",
        "        self.fc2 = nn.Linear(4, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "heFxBIsaGxDx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Client e Server do Flower\n",
        "\n",
        "Abaixo definimos o cliente e o servidor do Flower:\n",
        "- O **cliente federado** (FederatedClient) treina o modelo localmente e avalia.\n",
        "- O **servidor** coordena os rounds de treinamento. Ele envia parâmetros globais, recebe parâmetros locais dos clientes e agrega.\n",
        "\n",
        "Esta é a lógica principal do treinamento federado: nenhum dado sai do dispositivo (client), apenas parâmetros do modelo.\n",
        "Ao final de cada rodada, salvamos um checkpoint do modelo global.\n"
      ],
      "metadata": {
        "id": "Uh11Nb0BozEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Cliente Federado ###\n",
        "# O cliente recebe o modelo, dados locais (train_loader, test_loader) e realiza o treinamento local (fit),\n",
        "# além de avaliar (evaluate). Isso simula um dispositivo com seus próprios dados.\n",
        "class FederatedClient(NumPyClient):\n",
        "    def __init__(self, model, train_loader, test_loader, device):\n",
        "        self.model = model\n",
        "        self.train_loader = train_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.device = device\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        # Carrega parâmetros globais no modelo local e treina.\n",
        "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
        "        self.model.load_state_dict(state_dict, strict=True)\n",
        "        self.train(self.train_loader)\n",
        "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()], len(self.train_loader.dataset), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        # Carrega parâmetros globais e avalia no conjunto local de validação.\n",
        "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
        "        self.model.load_state_dict(state_dict, strict=True)\n",
        "        loss, accuracy = self.test(self.test_loader)\n",
        "        return float(loss), len(self.test_loader.dataset), {\"accuracy\": float(accuracy)}\n",
        "\n",
        "    def train(self, train_loader):\n",
        "      # Treinamento local do modelo no dispositivo\n",
        "      self.model.train()\n",
        "      criterion = nn.BCEWithLogitsLoss()\n",
        "      optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)\n",
        "\n",
        "      # Mais épocas locais para melhor convergência\n",
        "      for epoch in range(10):\n",
        "          for features, labels in train_loader:\n",
        "              features, labels = features.to(self.device), labels.to(self.device).float()\n",
        "              optimizer.zero_grad()\n",
        "              outputs = self.model(features).squeeze()\n",
        "              loss = criterion(outputs, labels)\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "\n",
        "    def test(self, test_loader):\n",
        "        # Avaliação local\n",
        "        self.model.eval()\n",
        "        criterion = nn.BCEWithLogitsLoss()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        test_loss = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for features, labels in test_loader:\n",
        "                features, labels = features.to(self.device), labels.to(self.device).float()\n",
        "                outputs = self.model(features).squeeze()\n",
        "                test_loss += criterion(outputs, labels).item()\n",
        "                preds = (torch.sigmoid(outputs) > 0.5).float()\n",
        "                correct += (preds == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "\n",
        "        accuracy = correct / total\n",
        "        return test_loss / len(test_loader), accuracy\n",
        "\n",
        "### Configuração do Cliente ###\n",
        "# Cada cliente receberá seu partition_id, seus dados locais, criará o modelo local e retornará um FederatedClient.\n",
        "def client_fn(context: Context) -> NumPyClient:\n",
        "    partition_id = context.node_config.get(\"partition_id\", 0)\n",
        "    train_data = processed_data[partition_id][\"train\"]\n",
        "    val_data = processed_data[partition_id][\"val\"]\n",
        "\n",
        "    input_dim = train_data[0].shape[1]\n",
        "    local_model = MigrationModel(input_dim=input_dim).to(DEVICE)\n",
        "\n",
        "    X_train, y_train = train_data\n",
        "    X_val, y_val = val_data\n",
        "\n",
        "    # Criação dos DataLoaders para treino e validação locais\n",
        "    train_dataset = list(zip(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32)))\n",
        "    val_dataset = list(zip(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.float32)))\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=32,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=32,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    return FederatedClient(local_model, train_loader, test_loader, DEVICE)\n",
        "\n",
        "### Estratégia com Salvamento ###\n",
        "# A estratégia FedAvg agrega os parâmetros dos clientes a cada rodada.\n",
        "# Ao final de cada rodada, salvamos o modelo global em um checkpoint.\n",
        "class SaveModelStrategy(FedAvg):\n",
        "    def __init__(self, model, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.model = model\n",
        "\n",
        "    def aggregate_fit(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        results: List[Tuple[flwr.server.client_proxy.ClientProxy, flwr.common.FitRes]],\n",
        "        failures: List[Union[Tuple[flwr.server.client_proxy.ClientProxy, flwr.common.FitRes], BaseException]],\n",
        "    ) -> Tuple[Optional[Parameters], dict]:\n",
        "        aggregated_parameters, aggregated_metrics = super().aggregate_fit(server_round, results, failures)\n",
        "\n",
        "        if aggregated_parameters is not None:\n",
        "            # Carrega parâmetros agregados no modelo global\n",
        "            aggregated_ndarrays = parameters_to_ndarrays(aggregated_parameters)\n",
        "            params_dict = zip(self.model.state_dict().keys(), aggregated_ndarrays)\n",
        "            state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
        "            self.model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "            # Salva o modelo global da rodada\n",
        "            checkpoint_filename = f\"model_round_{server_round}.pth\"\n",
        "            torch.save({\n",
        "                'input_dim': self.model.fc1.in_features,\n",
        "                'model_state_dict': self.model.state_dict()\n",
        "            }, checkpoint_filename)\n",
        "            print(f\"Model checkpoint saved: {checkpoint_filename}\")\n",
        "\n",
        "        return aggregated_parameters, aggregated_metrics\n",
        "\n",
        "### Configuração do Servidor ###\n",
        "# O servidor orquestra o treinamento federado.\n",
        "# Ele inicia o treinamento com o modelo global e configura a estratégia.\n",
        "def server_fn(context: Context) -> ServerAppComponents:\n",
        "    first_device = list(processed_data.keys())[0]\n",
        "    input_dim = processed_data[first_device][\"train\"][0].shape[1]\n",
        "\n",
        "    model = MigrationModel(input_dim=input_dim).to(DEVICE)\n",
        "    num_devices = len(processed_data)\n",
        "\n",
        "    strategy = SaveModelStrategy(\n",
        "        model=model,\n",
        "        fraction_fit=1.0,\n",
        "        fraction_evaluate=1.0,\n",
        "        min_fit_clients=num_devices,\n",
        "        min_evaluate_clients=num_devices,\n",
        "        min_available_clients=num_devices,\n",
        "    )\n",
        "    server_config = ServerConfig(num_rounds=10)\n",
        "    return ServerAppComponents(strategy=strategy, config=server_config)\n"
      ],
      "metadata": {
        "id": "cO123TLYHgUT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execução do treinamento federado\n",
        "\n",
        "Aqui chamamos `run_simulation` para simular o treinamento federado com o número de dispositivos igual ao número de entradas em `processed_data`.\n",
        "O server e o client são definidos pelas funções `server_fn` e `client_fn`.\n",
        "\n",
        "Ao final, teremos um modelo global treinado de forma federada, com pesos agregados das atualizações locais dos clients.\n"
      ],
      "metadata": {
        "id": "FughZ0AXo16y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_simulation(\n",
        "    server_app=ServerApp(server_fn=server_fn),\n",
        "    client_app=ClientApp(client_fn=client_fn),\n",
        "    num_supernodes=len(processed_data),\n",
        "    backend_config={\"client_resources\": {\"num_cpus\": 1, \"num_gpus\": 0.0}},\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_ZViViMMvgM",
        "outputId": "7e34228c-7d73-487c-e250-35c6d4c0b70a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:flwr:Asyncio event loop already running.\n",
            "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=10, no round_timeout\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
            "\u001b[36m(pid=2052)\u001b[0m 2024-12-08 19:13:06.715555: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=2052)\u001b[0m 2024-12-08 19:13:06.755932: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=2052)\u001b[0m 2024-12-08 19:13:06.768640: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(pid=2051)\u001b[0m 2024-12-08 19:13:10.510505: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
            "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
            "\u001b[92mINFO \u001b[0m:      Evaluation returned no results (`None`)\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 9 clients (out of 9)\n",
            "\u001b[36m(ClientAppActor pid=2052)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(pid=2051)\u001b[0m 2024-12-08 19:13:06.757678: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=2051)\u001b[0m 2024-12-08 19:13:06.800568: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=2051)\u001b[0m 2024-12-08 19:13:06.813486: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[36m(pid=2052)\u001b[0m 2024-12-08 19:13:10.739935: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[36m(ClientAppActor pid=2052)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\n",
            "\u001b[36m(ClientAppActor pid=2051)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 9 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 9 clients (out of 9)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model checkpoint saved: model_round_1.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 9 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 9 clients (out of 9)\n",
            "\u001b[36m(ClientAppActor pid=2052)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 9 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 9 clients (out of 9)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model checkpoint saved: model_round_2.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 9 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 9 clients (out of 9)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 9 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 9 clients (out of 9)\n",
            "\u001b[36m(ClientAppActor pid=2052)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 23x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model checkpoint saved: model_round_3.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 9 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 9 clients (out of 9)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 9 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 9 clients (out of 9)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model checkpoint saved: model_round_4.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(ClientAppActor pid=2052)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 9 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 9 clients (out of 9)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 9 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 9 clients (out of 9)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model checkpoint saved: model_round_5.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 9 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 6]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 9 clients (out of 9)\n",
            "\u001b[36m(ClientAppActor pid=2052)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 9 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 9 clients (out of 9)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model checkpoint saved: model_round_6.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 9 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 7]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 9 clients (out of 9)\n",
            "\u001b[36m(ClientAppActor pid=2052)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 9 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 9 clients (out of 9)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model checkpoint saved: model_round_7.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 9 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 8]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 9 clients (out of 9)\n",
            "\u001b[36m(ClientAppActor pid=2051)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 9 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 9 clients (out of 9)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model checkpoint saved: model_round_8.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 9 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 9]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 9 clients (out of 9)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 9 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 9 clients (out of 9)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model checkpoint saved: model_round_9.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 9 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 10]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 9 clients (out of 9)\n",
            "\u001b[36m(ClientAppActor pid=2052)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 9 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 9 clients (out of 9)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model checkpoint saved: model_round_10.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 9 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "\u001b[92mINFO \u001b[0m:      Run finished 10 round(s) in 49.98s\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.5248469896614552\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.40321817621588707\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.3104447778314352\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.24423078447580338\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.19025187194347382\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 6: 0.14682694617658854\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 7: 0.11237869411706924\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 8: 0.08583956956863403\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 9: 0.06537487404420972\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 10: 0.04976273118518293\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[36m(ClientAppActor pid=2051)\u001b[0m \u001b[93mWARNING \u001b[0m:   Deprecation Warning: The `client_fn` function must return an instance of `Client`, but an instance of `NumpyClient` was returned. Please use `NumPyClient.to_client()` method to convert it to `Client`.\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validação do modelo salvo\n",
        "\n",
        "Após o treinamento, carregamos o modelo salvo em `model_round_10.pth` e testamos alguns casos.\n",
        "Isso demonstra que o modelo global treinado federadamente aprendeu a lógica desejada.\n"
      ],
      "metadata": {
        "id": "KAvhNgN7o8Az"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "checkpoint = torch.load(\"model_round_10.pth\", map_location=DEVICE)\n",
        "input_dim = checkpoint['input_dim']\n",
        "model = MigrationModel(input_dim=input_dim).to(DEVICE)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "\n",
        "test_cases = [\n",
        "    [1, 1], # Deve ser True\n",
        "    [0, 0], # Deve ser False\n",
        "    [1, 0], # Deve ser False\n",
        "    [0, 1], # Deve ser False\n",
        "]\n",
        "\n",
        "test_tensor = torch.tensor(test_cases, dtype=torch.float32).to(DEVICE)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(test_tensor).squeeze()\n",
        "    probabilities = torch.sigmoid(outputs)\n",
        "    preds = (probabilities > 0.6).float()\n",
        "\n",
        "for i, (case, pred, prob) in enumerate(zip(test_cases, preds.cpu().numpy(), probabilities.cpu().numpy())):\n",
        "    print(f\"Caso {i+1}: Inputs={case}\")\n",
        "    print(f\"  Predição: {'True' if pred == 1.0 else 'False'} (prob: {prob:.4f})\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iN6pyX_HP_ee",
        "outputId": "297aa530-236b-4071-8444-eced53b66e82"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Caso 1: Inputs=[1, 1]\n",
            "  Predição: True (prob: 0.8301)\n",
            "\n",
            "Caso 2: Inputs=[0, 0]\n",
            "  Predição: False (prob: 0.0000)\n",
            "\n",
            "Caso 3: Inputs=[1, 0]\n",
            "  Predição: False (prob: 0.0142)\n",
            "\n",
            "Caso 4: Inputs=[0, 1]\n",
            "  Predição: False (prob: 0.0067)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-0dd967436ae8>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(\"model_round_10.pth\", map_location=DEVICE)\n"
          ]
        }
      ]
    }
  ]
}